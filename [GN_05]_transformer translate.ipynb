{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19906ac6",
   "metadata": {},
   "source": [
    "# 평가 조건\n",
    "1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.\n",
    "    - 데이터 정제, SentencePiece를 활용한 토큰화 및 데이터셋 구축의 과정이 지시대로 진행되었다.\n",
    "2. Transformer 번역기 모델이 정상적으로 구동된다.\n",
    "    - Transformer 모델의 학습과 추론 과정이 정상적으로 진행되어, 한-영 번역기능이 정상 동작한다.\n",
    "3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.\n",
    "    - 제시된 문장에 대한 그럴듯한 영어 번역문이 생성되며, 시각화된 Attention Map으로 결과를 뒷받침한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e4fb8",
   "metadata": {},
   "source": [
    "# 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e1ac46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ffc71d",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7e56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b4287",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae825af0",
   "metadata": {},
   "source": [
    "## 1. 중복 제거 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f7f27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "        \n",
    "    raw_data = pd.DataFrame({'korea':kor, 'english':eng})\n",
    "    \n",
    "    raw_data.drop_duplicates(inplace = True)\n",
    "    raw_data = raw_data[~raw_data.duplicated(subset='korea')]\n",
    "    raw_data = raw_data[~raw_data.duplicated(subset='english')]\n",
    "    \n",
    "    raw_data = raw_data.reset_index(drop=True)\n",
    "    \n",
    "    print('전체 중복:',sum(raw_data.duplicated()))\n",
    "    print('한국어 중복',sum(raw_data.duplicated(subset='korea')))\n",
    "    print('영어 중복',sum(raw_data.duplicated(subset='english')))\n",
    "    print('-----'*5)\n",
    "    print('중복을 제외한 데이터의 수',len(raw_data))\n",
    "    \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a9e5f",
   "metadata": {},
   "source": [
    "## 2. 단어 정제 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99184471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    sentence = re.sub(r'\\([^)]*\\)', r'', sentence) #괄호로 둘러싸인 부분 제거\n",
    "    sentence = re.sub(r\"([0-9?.!,])\", r\" \\1 \", sentence) #문장 내의 구둣점과 숫자 양 옆에 공백 추가\n",
    "    sentence = re.sub(r'[^a-zA-Z가-힣0-9?.!, ]+', r' ', sentence) #영문 알파벳, 한글, 숫자, 구둣점을 제외한 모든 문자를 제거\n",
    "    sentence = re.sub(r\"['\\n']+\", r\"\", sentence) #개행 문자 제거\n",
    "    sentence = re.sub(r'[\"   \"]+', \" \", sentence) #연속된 공백을 하나의 공백으로 변환\n",
    "\n",
    "    if s_token:\n",
    "        sentence = '<start> ' + sentence\n",
    "\n",
    "    if e_token:\n",
    "        sentence += ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324fed0",
   "metadata": {},
   "source": [
    "## 3. sentencepiece 토크나이저 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d75676",
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_temp_file = os.getenv('HOME') + '/aiffel/going_deeper/ko_spm.temp'\n",
    "en_temp_file = os.getenv('HOME') + '/aiffel/going_deeper/en_spm.temp'\n",
    "\n",
    "def generate_tokenizer(corpus,\n",
    "                        model_name,\n",
    "                        vocab_size,\n",
    "                        temp_file,\n",
    "                        lang=None,\n",
    "                        pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    \n",
    "    \n",
    "    with open(temp_file, 'w') as f:\n",
    "        for row in corpus:\n",
    "            f.write(str(row) + '\\n')\n",
    "            \n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        '--input={} \\\n",
    "        --model_prefix={} \\\n",
    "        --vocab_size={} \\\n",
    "        --accept_language={}\\\n",
    "        --pad_id={} \\\n",
    "        --bos_id={} \\\n",
    "        --eos_id={} \\\n",
    "        --unk_id={}'.format(temp_file, model_name, vocab_size+4, lang, pad_id, bos_id, eos_id, unk_id)\n",
    ")\n",
    "    \n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.Load('{}.model'.format(model_name))     \n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c532d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(model_name, corpus):\n",
    "    \n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.Load('{}.model'.format(model_name))\n",
    "    \n",
    "    corpus_list = []\n",
    "\n",
    "    for sen in tqdm(corpus):\n",
    "        corpus_list.append(s.EncodeAsIds(sen))\n",
    "        \n",
    "    with open(\"./{}.vocab\".format(model_name), 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "\n",
    "    return corpus_list, word_index, index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8c58d7",
   "metadata": {},
   "source": [
    "## 4. 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb76357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_lens(data, name):\n",
    "    \n",
    "    print('{} 데이터의 최소 길이 :{}'.format(name, min(len(l) for l in data)))\n",
    "    print('{} 데이터의 최대 길이 :{}'.format(name, max(len(l) for l in data)))\n",
    "    print('{} 데이터의 평균 길이 :{}'.format(name, sum(map(len, data))/len(data)))\n",
    "\n",
    "    plt.hist([len(s) for s in data], bins=50)\n",
    "    plt.xlabel('length of samples')\n",
    "    plt.ylabel('number of samples')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9318c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "    count = 0\n",
    "    for sentence in nested_list:\n",
    "        if(len(sentence) <= max_len):\n",
    "            count = count + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97854e8",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c98c9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 중복: 0\n",
      "한국어 중복 0\n",
      "영어 중복 0\n",
      "-------------------------\n",
      "중복을 제외한 데이터의 수 74849\n"
     ]
    }
   ],
   "source": [
    "raw_data = clean_corpus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7716c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74849/74849 [00:01<00:00, 49299.25it/s]\n",
      "100%|██████████| 74849/74849 [00:01<00:00, 38833.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어: 로보트 장치의 연간 판매액은 5 0 억 6 0 억달러로 추산되고 있다 . \n",
      "영어: <start> annual sales of robot units are estimated at 5 billion to 6 billion .  <end>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kor_corpus = []\n",
    "eng_corpus = []\n",
    "\n",
    "for sentence in tqdm(raw_data['korea']):\n",
    "    kor_corpus.append(preprocess_sentence(sentence))\n",
    "    \n",
    "for sentence in tqdm(raw_data['english']):\n",
    "    eng_corpus.append(preprocess_sentence(sentence, s_token=True, e_token=True))\n",
    "\n",
    "print(\"한국어:\", kor_corpus[33])   \n",
    "print(\"영어:\", eng_corpus[33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84258235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/going_deeper/ko_spm.temp         --model_prefix=korea_spm         --vocab_size=25004         --accept_language=ko        --pad_id=0         --bos_id=1         --eos_id=2         --unk_id=3\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/going_deeper/ko_spm.temp\n",
      "  input_format: \n",
      "  model_prefix: korea_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 25004\n",
      "  accept_language: ko\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/going_deeper/ko_spm.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 74812 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5010456\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1192\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 74811 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 151964 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 74811\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 190439\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 190439 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=80290 obj=12.0867 num_tokens=370223 num_tokens/piece=4.61107\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=67738 obj=10.9721 num_tokens=371439 num_tokens/piece=5.48347\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=50798 obj=10.9685 num_tokens=387944 num_tokens/piece=7.63699\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=50786 obj=10.9368 num_tokens=388296 num_tokens/piece=7.64573\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=38087 obj=11.0674 num_tokens=411095 num_tokens/piece=10.7936\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=38085 obj=11.0366 num_tokens=411107 num_tokens/piece=10.7945\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=28563 obj=11.211 num_tokens=435777 num_tokens/piece=15.2567\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=28563 obj=11.1734 num_tokens=435771 num_tokens/piece=15.2565\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=27504 obj=11.2004 num_tokens=438919 num_tokens/piece=15.9584\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=27504 obj=11.1954 num_tokens=438924 num_tokens/piece=15.9586\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korea_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korea_spm.vocab\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/going_deeper/en_spm.temp         --model_prefix=english_spm         --vocab_size=25004         --accept_language=en        --pad_id=0         --bos_id=1         --eos_id=2         --unk_id=3\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/going_deeper/en_spm.temp\n",
      "  input_format: \n",
      "  model_prefix: english_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 25004\n",
      "  accept_language: en\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/going_deeper/en_spm.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 74849 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=11376167\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9566% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=40\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999566\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 74849 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 78809 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 74849\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 44277\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 44277 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=33083 obj=11.2983 num_tokens=84276 num_tokens/piece=2.54741\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=25191 obj=8.91202 num_tokens=85344 num_tokens/piece=3.38788\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: english_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: english_spm.vocab\n"
     ]
    }
   ],
   "source": [
    "kor_sentencepiece = generate_tokenizer(kor_corpus, 'korea_spm', 25000, ko_temp_file, lang=\"ko\")\n",
    "eng_sentencepiece = generate_tokenizer(eng_corpus, 'english_spm', 25000, en_temp_file, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aebd763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_sentencepiece.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00a18e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74849/74849 [00:01<00:00, 37744.04it/s]\n",
      "100%|██████████| 74849/74849 [00:03<00:00, 23116.96it/s]\n"
     ]
    }
   ],
   "source": [
    "korea_corpus_list, ko_word_index, ko_index_word = sp_tokenize('korea_spm', kor_corpus)\n",
    "english_corpus_list, en_word_index, en_index_word = sp_tokenize('english_spm', eng_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c418015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[966, 421, 501, 568, 7, 1228, 1685, 8, 1080, 220, 2616, 915, 36, 10122, 410]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korea_corpus_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0e28bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국어 데이터의 최소 길이 :0\n",
      "한국어 데이터의 최대 길이 :132\n",
      "한국어 데이터의 평균 길이 :26.47021336290398\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 264,
       "width": 394
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lens(korea_corpus_list, '한국어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f48cb611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 최소 길이 :6\n",
      "영어 데이터의 최대 길이 :142\n",
      "영어 데이터의 평균 길이 :41.61604029445951\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 264,
       "width": 394
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lens(english_corpus_list, '영어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "223428d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 97.6151985998477\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "below_threshold_len(max_len, korea_corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "076e428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 73.56544509612687\n"
     ]
    }
   ],
   "source": [
    "max_len = 50\n",
    "below_threshold_len(max_len, english_corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d92e9956",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_data = tf.keras.preprocessing.sequence.pad_sequences(korea_corpus_list, padding='post', maxlen= max_len)\n",
    "eng_data = tf.keras.preprocessing.sequence.pad_sequences(english_corpus_list, padding='post', maxlen= max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d47743ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74849, 50)\n",
      "(74849, 50)\n"
     ]
    }
   ],
   "source": [
    "print(kor_data.shape)\n",
    "print(eng_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd9fca",
   "metadata": {},
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fd797",
   "metadata": {},
   "source": [
    "### positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ed0b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db8fca",
   "metadata": {},
   "source": [
    "### MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e32757b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model) # Linear Layer\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "\n",
    "        QK = tf.matmul(Q,K, transpose_b = True)\n",
    "        \n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9) \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis = -1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "        \n",
    "        \n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0,2,1,3])\n",
    "        \n",
    "        \n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0,2,1,3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "    \n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "      \n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3778bf",
   "metadata": {},
   "source": [
    "### PoswiseFeedForwardNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5838421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9db41f",
   "metadata": {},
   "source": [
    "### Encoder & Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59f723d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "057c8306",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5366a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cb8f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8756a7",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63f675c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=0.2,\n",
    "                 shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        \n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "\n",
    "\n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3f5d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954750e",
   "metadata": {},
   "source": [
    "### 학습 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66b517d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2acfdea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6166f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b72022",
   "metadata": {},
   "source": [
    "### 학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d5d599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0263ff5",
   "metadata": {},
   "source": [
    "### 학습 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cb8569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()\n",
    "        \n",
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=kor_data.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(eng_data.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "# 번역 생성 및 Attention 시각화 결합\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c816821f",
   "metadata": {},
   "source": [
    "# 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0d775af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 256\n",
    "num_heads = 4\n",
    "d_ff = 1024\n",
    "pos_len = max_len\n",
    "vocab_size = 25000\n",
    "drop_rate = 0.2\n",
    "\n",
    "\n",
    "examples = [\n",
    "    \"오바마는 대통령이다.\", \"시민들은 도시 속에 산다.\",\n",
    "    \"커피는 필요 없다.\", \"일곱 명의 사망자가 발생했다.\",\n",
    "    \"가족을 사랑한다.\",\"오늘 날씨는 덥다.\"]\n",
    "\n",
    "transformer = Transformer(num_layers,\n",
    "                    d_model,\n",
    "                    num_heads,\n",
    "                    d_ff,\n",
    "                    vocab_size,\n",
    "                    vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout = drop_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "473645b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 1170/1170 [02:57<00:00,  6.59it/s, Loss 3.9657]\n",
      "Epoch  2: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 3.1427]\n",
      "Epoch  3: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 2.7741]\n",
      "Epoch  4: 100%|██████████| 1170/1170 [02:46<00:00,  7.02it/s, Loss 2.4900]\n",
      "Epoch  5: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 2.2388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: marks the first time , the president is the president slated to be president , obama s president , the illinois senator said . obama is the president s becoming president , he wrote . <end> <end\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: city , and the city s largest city , the city s largest city , the city s largest city , has a largest city , the city s largest city in the city . <end> <\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: coffee , no one of coffee , you don t have any coffee , coffee , don t be coffee , coffee , coffee , or coffee , don t be coffee , coffee said . <end> <\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: was killed in the seven death of 2 0 people , wounded , and wounded , killing at least seven people , wounding  ⁇  , 2 0 0  ⁇  <end> <\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: love , 2 0 0 9 . . . . . . . . . . . . . . . . . <end> <end\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: today , the weather is about today . . . . . . . . . . . . . . . . . <end> <end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6: 100%|██████████| 1170/1170 [02:47<00:00,  6.98it/s, Loss 2.0088]\n",
      "Epoch  7: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 1.7933]\n",
      "Epoch  8: 100%|██████████| 1170/1170 [02:46<00:00,  7.02it/s, Loss 1.5972]\n",
      "Epoch  9: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 1.4287]\n",
      "Epoch 10: 100%|██████████| 1170/1170 [02:47<00:00,  7.01it/s, Loss 1.2788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: , obama is a presidential candidate . obama . president obama . president obama is similar to obama , obama said similar to obama . president obama . according to cnn s kyung lah . <end> <end>\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: s , street storms around the city of street . . . . . . . . s . . . s becoming a big stretch of your city . <end> <\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: s at work . don t be coffee . <end> . <end> . <end> <end> . <end> <end> <end> <end> <end> <end> <end>\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ed at the seven deaths of  ⁇  , injured 8  ⁇  others , injuring seven others , injuring seven others , injuring seven others have died in seven . <end> <\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: , a family person in the world , i have been brains with love you . a love brain , i and i d have a love you , d . c . . <end> <\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: s today s weather forecast , but weather is weather seen as hot weather , the weather is heading today to the weather hot , today s weather forecast for the weather today . hung <end> <end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1170/1170 [02:47<00:00,  6.98it/s, Loss 1.1367]\n",
      "Epoch 12: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 1.0113]\n",
      "Epoch 13: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 0.8995]\n",
      "Epoch 14: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 0.8028]\n",
      "Epoch 15: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.7200]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: is the first time , obama said tuesday at a cnn conference . obama is the president s word of presidential nominee , which is obama s word that would be president obama s president , obama said tuesday . <end> <\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: deaths on a mountainous city where citizens can grow into the city s main city , are busy amid global sleep , such a city where they slew in a mountain turned city city city . <end> <\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: s at work . at the company , don t be rather than work . don t be , at work , depp says at work . otherwise , your work else <end> <end>\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: was killed in the seventh of seven others . at least  ⁇  0 people , injuring , others said , among others members of the ⁇  , no officials . <end> <\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: daniel cuba s family and daniele a family finish on job together , a family awaits a love daniele deal , you are loved by a love daniele , illinois , i wonder . <end> <\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: s today , weather forecasts our weather forecasts . i m catching up for up forday , but weathered the weather for sure today , that s thin weather today is rush . <end> <\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 1170/1170 [02:47<00:00,  6.97it/s, Loss 0.6478]\n",
      "Epoch 17: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 0.5890]\n",
      "Epoch 18: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 0.5383]\n",
      "Epoch 19: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.4924]\n",
      "Epoch 20: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.4567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: was the first president . obama . obama . cnn . obama . obama . president obama . according to obama , obama s words , where obama is president obama s presidential visit . <end>\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: deaths there s a turn in . . . . . citizens can be in the city but managednight , ap network ho da turned up there to the city s mountainous urban don . <end>\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: no coffee for you need a coffee isn t necessary . you need no donations . <end> <end> <end> <end> <end> <end> <end> <end> <end> <end>\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ed at seven other lives , seven other dead were injured in seven deaths , but seven others were killed in the blast shook cause care sector in the seven deaths seven others seven people . <end> <\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: daniel de love daniel de love daniel , a family and day , i have the family and our family and our family and our family and our family and our family guys never , i own him wonders . <end> on\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: this morning <end> the weather is today . <end> <end> <end> <end> <end> we got today . <end> <end> we allday <end> <end> <end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1170/1170 [02:48<00:00,  6.96it/s, Loss 0.4229]\n",
      "Epoch 22: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.3948]\n",
      "Epoch 23: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.3683]\n",
      "Epoch 24: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.3456]\n",
      "Epoch 25: 100%|██████████| 1170/1170 [02:46<00:00,  7.01it/s, Loss 0.3314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: was the first foreign . obama . obama . . . . page , obama said tuesday . obama . obama is the presidential candidate and obama will be presidential candidate . <end> <end>\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: s legislature , turn yong in town , 1 8 .  ⁇  billion people turned into a big city but standing to sleep up in town city but people they know the city s maine . <end> <\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: is not a coffee for . no matter who don t need coffee . at the cup of coffee requires coffee . at other don t be coffee , at the 6 0 put in reasons . <end> <\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ed at seven others , four others were killed in seven others , while seven others were killed in seven others , killing nearly seven others , the officials . <end> ⁇ \n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: s 2 0 th front at our world , and 3 0 days . our family s finally killing 3 . maren in front of our family s finally love relationships . <end> <\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: s today , but sending weather today , sending 3 8 th hurricane management , sending today , sending today s weather today . <end> <end>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1170/1170 [02:47<00:00,  6.97it/s, Loss 0.3106]\n",
      "Epoch 27: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.2968]\n",
      "Epoch 28: 100%|██████████| 1170/1170 [02:47<00:00,  6.99it/s, Loss 0.2834]\n",
      "Epoch 29: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.2729]\n",
      "Epoch 30: 100%|██████████| 1170/1170 [02:47<00:00,  7.00it/s, Loss 0.2605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: was the only foreign . obama . obama . everyone will be president taking president . obama s words carried president , obama s leading presidential nominating contests , obama . <end>\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: mountains and pat entertainment is a big turn in a city where citizens can be blew into a main city in the city to the city s san . <end> here 8 fearful water breaking . <end> <end\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: is no medical needed , there is no motion than a coffee for our works . there isn t a work chair for coffee at coffee lists , that don t you have coffee for your health information . <end> <\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ed at seven lives in seven other countries , leaving among them members of the fighting . but killing seven others were malve involvement , killing at all behind no injuries , the state <end> state\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: runs . i loved our loved one person , cnn days . i loved our guy s loved , our iran s finally killing 2 3 days in love final . <end> <\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: ed today s weather when weather is headed today , the weather is headed today , he s heading up today , sandra s john jay de s john hurt in retail hearing . <end> <\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, kor_data.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "                    train_step(kor_data[idx:idx+BATCH_SIZE],\n",
    "                                eng_data[idx:idx+BATCH_SIZE],\n",
    "                                transformer,\n",
    "                                optimizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "        \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        for example in examples:\n",
    "            translate(example, transformer, kor_sentencepiece, eng_sentencepiece, plot_attention=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25da54a",
   "metadata": {},
   "source": [
    "# 결과 비교\n",
    "\n",
    "| Input            | Transformer+sentencepiece                                                                                                                                                                                 | Seq2Seq+Mecab |\n",
    "| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |\n",
    "| 오바마는 대통령이다.      | was the only foreign . obama . obama . everyone will be president taking president . obama s words carried president , obama s leading presidential nominating contests , obama . <end>               | obama is the president . <end> |\n",
    "| 시민들은 도시 속에 산다.   | mountains and pat entertainment is a big turn in a city where citizens can be blew into a main city in the city to the city s san . <end> here 8 fearful water breaking . <end> <end                  | civilians are in cities , hurled high of the city . <end> |\n",
    "| 커피는 필요 없다.       | is no medical needed , there is no motion than a coffee for our works . there isn t a work chair for coffee at coffee lists , that don t you have coffee for your health information . <end> <        | there s no idea of the right now . <end> |\n",
    "| 일곱 명의 사망자가 발생했다. | ed at seven lives in seven other countries , leaving among them members of the fighting . but killing seven others were malve involvement , killing at all behind no injuries , the state <end> state | seven dead was killed . <end> |\n",
    "| 가족을 사랑한다.        | runs . i loved our loved one person , cnn days . i loved our guy s loved , our iran s finally killing 2 3 days in love final . <end> <                                                                | family love love of family . <end> |\n",
    "| 오늘 날씨는 덥다.       | ed today s weather when weather is headed today , the weather is headed today , he s heading up today , sandra s john jay de s john hurt in retail hearing . <end> <                                  | today weather has forced to today <end> |\n",
    "\n",
    "    \n",
    "앞 선 노드의 결과와 비교하였을때, Seq2Seq+Mecab으로 했을때 오히려 번역의 품질이 더 좋았습니다.\n",
    "\n",
    "sentencepiece의 경우 한국어를 제대로 토큰화하지 못한것으로 생각됩니다.\n",
    "\n",
    "추가적으로 Transformer+Mecab을 시도해보고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ef97e",
   "metadata": {},
   "source": [
    "# 추가시도 1 : Transformer+Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be3cecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "def tokenization(corpus, kor = False, num_words=None):\n",
    "    if kor:\n",
    "        mecab = Mecab()\n",
    "        sentence = []\n",
    "        for i in tqdm(corpus):\n",
    "            sentence.append(mecab.morphs(i))\n",
    "        corpus = sentence\n",
    "        \n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = num_words, filters='',oov_token='<unk>')\n",
    "    \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    return tensor, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3ad04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74849/74849 [00:11<00:00, 6562.64it/s]\n"
     ]
    }
   ],
   "source": [
    "kor_tensor, kor_tokenizer = tokenization(kor_corpus, kor = True, num_words = 25000)\n",
    "eng_tensor, eng_tokenizer = tokenization(eng_corpus, kor = False, num_words = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07c4d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_data = tf.keras.preprocessing.sequence.pad_sequences(kor_tensor, padding='post', maxlen= max_len)\n",
    "eng_data = tf.keras.preprocessing.sequence.pad_sequences(eng_tensor, padding='post', maxlen= max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fbf37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()\n",
    "        \n",
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate1(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    mecab = Mecab()\n",
    "    \n",
    "    sentence = mecab.morphs(sentence)\n",
    "    \n",
    "    pieces = sentence\n",
    "    _input = src_tokenizer.texts_to_sequences([sentence])\n",
    "    \n",
    "    sos_idx = tgt_tokenizer.word_index['<start>']\n",
    "    eos_idx = tgt_tokenizer.word_index['<end>']\n",
    "    \n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences(_input,\n",
    "                                                           maxlen=kor_data.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([sos_idx], 0)\n",
    "    \n",
    "    for i in range(eng_data.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if predicted_id == eos_idx:\n",
    "            result = tgt_tokenizer.sequences_to_texts([ids])\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "# 번역 생성 및 Attention 시각화 결합\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate1(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "#     if plot_attention:\n",
    "#         visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8c04e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a520a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 256\n",
    "num_heads = 4\n",
    "d_ff = 1024\n",
    "pos_len = max_len\n",
    "vocab_size = 25000\n",
    "drop_rate = 0.2\n",
    "\n",
    "\n",
    "examples = [\n",
    "    \"오바마는 대통령이다.\", \"시민들은 도시 속에 산다.\",\n",
    "    \"커피는 필요 없다.\", \"일곱 명의 사망자가 발생했다.\",\n",
    "    \"가족을 사랑한다.\",\"오늘 날씨는 덥다.\"]\n",
    "\n",
    "transformer = Transformer(num_layers,\n",
    "                    d_model,\n",
    "                    num_heads,\n",
    "                    d_ff,\n",
    "                    vocab_size,\n",
    "                    vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout = drop_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d286a1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 1170/1170 [02:56<00:00,  6.62it/s, Loss 5.6076]\n",
      "Epoch  2: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 4.7284]\n",
      "Epoch  3: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 4.3234]\n",
      "Epoch  4: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 4.0290]\n",
      "Epoch  5: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 3.7810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: ['obama is a president .']\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: ['they are <unk> in cities .']\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: ['coffee is a second place .']\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ['seven people were killed in seven seven people .']\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: ['family loved ones .']\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: ['the weather is the weather .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  6: 100%|██████████| 1170/1170 [02:46<00:00,  7.02it/s, Loss 3.5571]\n",
      "Epoch  7: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 3.3401]\n",
      "Epoch  8: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 3.1291]\n",
      "Epoch  9: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 2.9242]\n",
      "Epoch 10: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 2.7266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: ['obama s president obama has obama s own .']\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: ['citizens are in cities .']\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: ['it s not a second thing or <unk> .']\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ['seven soldiers were killed .']\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: ['family , love in love , love with love .']\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: ['it s the weather <unk> .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 1170/1170 [02:46<00:00,  7.03it/s, Loss 2.5438]\n",
      "Epoch 12: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 2.3752]\n",
      "Epoch 13: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 2.2251]\n",
      "Epoch 14: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 2.0937]\n",
      "Epoch 16: 100%|██████████| 1170/1170 [02:46<00:00,  7.02it/s, Loss 1.8752]\n",
      "Epoch 17: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.7949]\n",
      "Epoch 18: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.7164]\n",
      "Epoch 19: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.6398]\n",
      "Epoch 20: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.5734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: ['obama s camp .']\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: ['citizens show up to one of the city .']\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: ['it shouldn t be a <unk> .']\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ['seven soldiers were killed .']\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: ['family love']\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: ['i did it today , it s my life .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 1170/1170 [02:46<00:00,  7.03it/s, Loss 1.5562]\n",
      "Epoch 22: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.4355]\n",
      "Epoch 23: 100%|██████████| 1170/1170 [02:46<00:00,  7.03it/s, Loss 1.4482]\n",
      "Epoch 24: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.3859]\n",
      "Epoch 25: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.2761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: ['obama s camp .']\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: ['citizens are in urban towns and says most of the city government won']\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: ['coffee is not a <unk> .']\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ['seven soldiers were killed .']\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: ['at you .']\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: ['it s the day i m like i .']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 1170/1170 [02:46<00:00,  7.03it/s, Loss 1.2123]\n",
      "Epoch 27: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.2523]\n",
      "Epoch 28: 100%|██████████| 1170/1170 [02:46<00:00,  7.03it/s, Loss 1.1189]\n",
      "Epoch 29: 100%|██████████| 1170/1170 [02:46<00:00,  7.03it/s, Loss 1.0853]\n",
      "Epoch 30: 100%|██████████| 1170/1170 [02:46<00:00,  7.04it/s, Loss 1.0208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: ['obama s campaign would begin either .']\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: ['citizens show up most of <unk>']\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: ['at least one point , it s no .']\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ['seven soldiers were killed sunday .']\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: ['my family love .']\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: ['it s the weather in the city s weather .']\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, kor_data.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "                    train_step(kor_data[idx:idx+BATCH_SIZE],\n",
    "                                eng_data[idx:idx+BATCH_SIZE],\n",
    "                                transformer,\n",
    "                                optimizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "        \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        for example in examples:\n",
    "            translate(example, transformer, kor_tokenizer, eng_tokenizer, plot_attention=False)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "265c3811",
   "metadata": {},
   "source": [
    "# 결과 비교\n",
    "\n",
    "| Input            | Transformer+sentencepiece                                                                                                                                                                                 | Transformer+Mecab |\n",
    "| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------- |\n",
    "| 오바마는 대통령이다.      | was the only foreign . obama . obama . everyone will be president taking president . obama s words carried president , obama s leading presidential nominating contests , obama . <end>               | obama s campaign would begin either . |\n",
    "| 시민들은 도시 속에 산다.   | mountains and pat entertainment is a big turn in a city where citizens can be blew into a main city in the city to the city s san . <end> here 8 fearful water breaking . <end> <end                  | citizens show up most of <unk> |\n",
    "| 커피는 필요 없다.       | is no medical needed , there is no motion than a coffee for our works . there isn t a work chair for coffee at coffee lists , that don t you have coffee for your health information . <end> <        | at least one point , it s no . |\n",
    "| 일곱 명의 사망자가 발생했다. | ed at seven lives in seven other countries , leaving among them members of the fighting . but killing seven others were malve involvement , killing at all behind no injuries , the state <end> state | seven soldiers were killed sunday . |\n",
    "| 가족을 사랑한다.        | runs . i loved our loved one person , cnn days . i loved our guy s loved , our iran s finally killing 2 3 days in love final . <end> <                                                                | my family love . |\n",
    "| 오늘 날씨는 덥다.       | ed today s weather when weather is headed today , the weather is headed today , he s heading up today , sandra s john jay de s john hurt in retail hearing . <end> <                                  | it s the weather in the city s weather .|\n",
    "\n",
    "\n",
    "sentencepiece로 토크나이저를 만들었을때보다, Mecab을 이용한것이 더 자연스러운 번역을 했다고 생각합니다.\n",
    "\n",
    "또한 현재 30epoch로 실험을 하였는데, 오히려 적은 epoch일때, 더 좋은 결과들이 나온것을 알 수 있었습니다.\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "따라서 이번에는 epoch 수를 줄이고, 하이퍼 파라미터의 수를 조정하여 다시 한번 시도해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083a39fa",
   "metadata": {},
   "source": [
    "# 추가 시도 2 : 에포크 수를 줄이고, 하이퍼 파라미터 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb435faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d323a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "d_model = 256\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "pos_len = max_len\n",
    "vocab_size = 25000\n",
    "drop_rate = 0.2\n",
    "\n",
    "\n",
    "examples = [\n",
    "    \"오바마는 대통령이다.\", \"시민들은 도시 속에 산다.\",\n",
    "    \"커피는 필요 없다.\", \"일곱 명의 사망자가 발생했다.\",\n",
    "    \"가족을 사랑한다.\",\"오늘 날씨는 덥다.\"]\n",
    "\n",
    "transformer = Transformer(num_layers,\n",
    "                    d_model,\n",
    "                    num_heads,\n",
    "                    d_ff,\n",
    "                    vocab_size,\n",
    "                    vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout = drop_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "952b264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch  1: 100%|██████████| 1170/1170 [02:26<00:00,  7.98it/s, Loss 5.7432]\n",
      "Epoch  2: 100%|██████████| 1170/1170 [02:21<00:00,  8.25it/s, Loss 4.8960]\n",
      "Epoch  3: 100%|██████████| 1170/1170 [02:22<00:00,  8.23it/s, Loss 4.5176]\n",
      "Epoch  4: 100%|██████████| 1170/1170 [02:22<00:00,  8.22it/s, Loss 4.2498]\n",
      "Epoch  5: 100%|██████████| 1170/1170 [02:22<00:00,  8.22it/s, Loss 4.0320]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: ['obama is the president .']\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: ['the city of the city s city .']\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: ['coffee is not a good .']\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: ['the dead were killed .']\n",
      "Input: 가족을 사랑한다.\n",
      "Predicted translation: ['family family love']\n",
      "Input: 오늘 날씨는 덥다.\n",
      "Predicted translation: ['the weather is the weather .']\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, kor_data.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "                    train_step(kor_data[idx:idx+BATCH_SIZE],\n",
    "                                eng_data[idx:idx+BATCH_SIZE],\n",
    "                                transformer,\n",
    "                                optimizer)\n",
    "    \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "        \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        for example in examples:\n",
    "            translate(example, transformer, kor_tokenizer, eng_tokenizer, plot_attention=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427df5ba",
   "metadata": {},
   "source": [
    "# 결과 비교\n",
    "\n",
    "| Parameter  |      Model1     |      Model2     |\n",
    "| ---------- | --------------- | --------------- |\n",
    "| num_layers | 4               | 2               |\n",
    "| d_model    | 256             | 256             |\n",
    "| num_heads  | 4               | 8               |\n",
    "| d_ff       | 1024            | 2048            |\n",
    "| pos_len    | max_len         | max_len         |\n",
    "| vocab_size | 25000           | 25000           |\n",
    "| drop_rate  | 0.2             | 0.2             |\n",
    "| BATCH_SIZE | 64              | 64              |\n",
    "| EPOCHS     | 30              | 5               |\n",
    "\n",
    "\n",
    "\n",
    "| Input            |   Seq2Seq+Mecab |             Transformer Model1                   |             Transformer Model2           |\n",
    "| ---------------- | ------------------ |---------------------- | ----------------------------- |\n",
    "| 오바마는 대통령이다.      | obama is the president . <end> |obama s campaign would begin either .    | obama is the president .      |\n",
    "| 시민들은 도시 속에 산다.   | civilians are in cities , hurled high of the city . <end> |citizens show up most of <unk>           | the city of the city s city . |\n",
    "| 커피는 필요 없다.       |there s no idea of the right now . <end> | at least one point , it s no .           | coffee is not a good .        |\n",
    "| 일곱 명의 사망자가 발생했다. | seven dead was killed . <end> |seven soldiers were killed sunday .      | the dead were killed .        |\n",
    "| 가족을 사랑한다.        |family love love of family . <end> | my family love .                         | family family love            |\n",
    "| 오늘 날씨는 덥다.       | today weather has forced to today <end> |it s the weather in the city s weather . | the weather is the weather .  |\n",
    "    \n",
    "num_layers, num_heads, EPOCHS의 수만 바꿔서 실험을 해보았습니다.\n",
    "    \n",
    "앞서 예상한대로 오히려 적은 에포크일때, 좋은 번역의 성능을 보여줬습니다. 첫번째 문장인 '오바마는 대통령이다.'는 올바르게 번역한 것을 볼 수 있습니다. 또한, 'city', 'coffee', 'family' 등 주요 단어들을 제대로 번역한 것을 확인 할 수 있었습니다. \n",
    "    \n",
    "또한 Seq2Seq+Mecab의 성능도 좋았습니다. 이것은 한국어에서는 sentencepiece와 같은 토크나이저보다는 mecab과 같은 한국어의 특성에 맞는 토크나이저의 성능이 더 좋다는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70cb3a0",
   "metadata": {},
   "source": [
    "# 전체 회고\n",
    "- 트랜스포머는 정말 어려운것 같습니다.\n",
    "- 이번 노드에서는 설명도 잘해주었지만, 트랜스포머를 제대로 알아야 이후에 나올 모델들을 제대로 이해할 수 있기에 많은 시간을 투자하였습니다.\n",
    "- 개인적으로는 아직 많이 부족하다고 생각이 되며, 트랜스포머의 개념과 코드적인 이해를 위해 좀 더 시간을 할애해야 할 것으로 생각됩니다.\n",
    "\n",
    "- 한국어는 조사라는 개념이 있기 때문에 sentencepiece같은 토크나이저보다는 mecab과 같은 한국어의 특성이 반영된 토크나이저를 쓰는것이 더 좋다고 생각이 됩니다.\n",
    "- 이번 노드에서는 vocab_size를 고정하고 실험을 하였는데, 늘렸을때의 성능도 체크해보고 싶습니다.\n",
    "- 하이퍼 파라미터를 조정한다면, 훨씬 더 품질이 좋은 번역이 나올 것으로 생각됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63c8d1",
   "metadata": {},
   "source": [
    "# 참고 자료\n",
    "- 이전 노드\n",
    "- https://wikidocs.net/31379\n",
    "- https://velog.io/@nawnoes/Transformer%EB%A1%9C-%ED%95%9C%EA%B5%AD%EC%96%B4-%EC%98%81%EC%96%B4-%EB%B2%88%EC%97%AD-%EB%AA%A8%EB%8D%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0\n",
    "- https://wikidocs.net/166832\n",
    "- https://ariz1623.tistory.com/304 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
